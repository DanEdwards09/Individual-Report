\appendix

\section{Graph-Aware SAT Solving Implementation Code}
\label{appendix:graph-aware-implementation}

\subsection{Enhanced Solver Architecture for Trade-off Management}
\label{appendix:enhanced-solver-architecture}

\begin{lstlisting}[language=Python, caption=Enhanced Solver Architecture for Performance-Robustness Trade-offs]
class GraphAwareSATSolver(DPLLSolver):
    """
    Graph-aware SAT solver optimized for trading average-case performance 
    for worst-case robustness in graph coloring applications.
    """
    
    def __init__(self, robustness_mode: bool = True, verbose: bool = False):
        super().__init__(verbose=verbose)
        self.robustness_mode = robustness_mode
        
        # Trade-off management components
        self.overhead_tracker = OverheadTracker()
        self.robustness_monitor = RobustnessMonitor()
        
        # Graph-aware processing components
        self.graph_analyzer = None
        self.centrality_computer = None
        self.priority_manager = None
        
        # Performance-robustness statistics
        self.tradeoff_stats = {
            'preprocessing_overhead': 0.0,
            'analysis_time': 0.0,
            'enhanced_decisions': 0,
            'robustness_activations': 0,
            'fallback_events': 0,
            'success_rate_improvement': 0.0
        }
        
        # Configuration for controlled trade-off behavior
        self.overhead_budget = 1.5  # Maximum acceptable overhead factor
        self.robustness_threshold = 0.95  # Minimum success rate target
        
    def solve_with_tradeoff_analysis(self, vertices: List[int], 
                                   edges: List[Tuple[int, int]], 
                                   num_colors: int, 
                                   timeout: float = 300.0) -> TradeoffResult:
        """
        Main solving method with comprehensive trade-off analysis and validation.
        """
        start_time = time.time()
        
        # Initialize trade-off monitoring
        self.overhead_tracker.start_monitoring()
        self.robustness_monitor.initialize(vertices, edges, num_colors)
        
        # Phase 1: Graph analysis with overhead tracking
        if self.robustness_mode:
            analysis_result = self._perform_graph_analysis(vertices, edges)
            self.tradeoff_stats['analysis_time'] = analysis_result.time_cost
            self.tradeoff_stats['preprocessing_overhead'] = analysis_result.overhead_factor
        else:
            analysis_result = None
        
        # Phase 2: SAT encoding with robustness enhancements
        cnf_formula = self._encode_graph_coloring_with_enhancements(
            vertices, edges, num_colors, analysis_result
        )
        
        # Phase 3: Solving with trade-off monitoring
        solving_start = time.time()
        is_satisfiable, assignment = self._solve_with_robustness_tracking(
            cnf_formula, timeout - (solving_start - start_time)
        )
        solving_time = time.time() - solving_start
        
        # Phase 4: Trade-off analysis and result construction
        total_time = time.time() - start_time
        tradeoff_analysis = self._analyze_performance_robustness_tradeoff(
            total_time, solving_time, is_satisfiable
        )
        
        return TradeoffResult(
            satisfiable=is_satisfiable,
            assignment=self._convert_sat_to_coloring(assignment, vertices, num_colors),
            tradeoff_analysis=tradeoff_analysis,
            robustness_metrics=self.robustness_monitor.get_metrics(),
            overhead_breakdown=self.overhead_tracker.get_breakdown()
        )
\end{lstlisting}

\subsection{Threshold Analysis Implementation}
\label{appendix:threshold-analysis}

\begin{lstlisting}[language=Python, caption=Threshold Analysis for Trade-off Boundaries]
class ThresholdAnalyser:
    """
    Evaluates break-even points where enhanced solver overhead becomes 
    justified by reliability improvements across different operational contexts.
    """
    
    def __init__(self):
        self.threshold_results = []
        self.sensitivity_data = []
        
    def evaluate_deployment_thresholds(self, test_suite: List[Dict], 
                                     baseline_solver, enhanced_solver) -> Dict:
        """
        Systematic threshold identification for deployment guidance.
        """
        threshold_analysis = {
            'parameter_sweeps': {},
            'break_even_points': {},
            'deployment_recommendations': {},
            'sensitivity_analysis': {}
        }
        
        # Graph density threshold analysis
        density_thresholds = self._analyze_density_thresholds(
            test_suite, baseline_solver, enhanced_solver
        )
        threshold_analysis['parameter_sweeps']['density'] = density_thresholds
        
        # Problem size threshold analysis
        size_thresholds = self._analyze_size_thresholds(
            test_suite, baseline_solver, enhanced_solver
        )
        threshold_analysis['parameter_sweeps']['size'] = size_thresholds
        
        # Connectivity threshold analysis
        connectivity_thresholds = self._analyze_connectivity_thresholds(
            test_suite, baseline_solver, enhanced_solver
        )
        threshold_analysis['parameter_sweeps']['connectivity'] = connectivity_thresholds
        
        # Calculate break-even points
        threshold_analysis['break_even_points'] = self._calculate_break_even_points(
            threshold_analysis['parameter_sweeps']
        )
        
        # Generate deployment recommendations
        threshold_analysis['deployment_recommendations'] = self._generate_deployment_guidance(
            threshold_analysis['break_even_points']
        )
        
        # Perform sensitivity analysis
        threshold_analysis['sensitivity_analysis'] = self._perform_sensitivity_analysis(
            threshold_analysis['parameter_sweeps']
        )
        
        return threshold_analysis
    
    def _analyze_density_thresholds(self, test_suite: List[Dict], 
                                  baseline_solver, enhanced_solver) -> Dict:
        """
        Analyse how graph density affects trade-off attractiveness.
        """
        density_analysis = {
            'density_ranges': [],
            'overhead_ratios': [],

\subsection{Enhanced CDCL Solver Class Architecture}
\label{appendix:enhanced-cdcl-class}

\begin{lstlisting}[language=Python, caption=Enhanced CDCL Solver Class Architecture]
class EnhancedCDCLSolver(DPLLSolver):
    def __init__(self, enable_graph_awareness: bool = True, verbose: bool = False):
        super().__init__(verbose=verbose)
        self.enable_graph_awareness = enable_graph_awareness
        
        # Graph analysis components
        self.graph_analyzer = None
        self.variable_priority_order = None
        
        # Enhanced statistics and monitoring
        self.enhanced_stats = {
            'graph_analysis_time': 0.0,
            'preprocessing_reductions': 0,
            'enhanced_decisions': 0,
            'priority_cache_hits': 0,
            'fallback_activations': 0
        }
        
        # Performance tuning parameters
        self.centrality_weights = {'degree': 0.7, 'betweenness': 0.3}
        self.preprocessing_threshold = 50  # vertices
\end{lstlisting}

\subsection{Centrality-Based Variable Priority System}
\label{appendix:centrality-priority}

\begin{lstlisting}[language=Python, caption=Centrality-Based Variable Priority System]
def _initialize_graph_analysis(self, vertices: List[int], edges: List[Tuple[int, int]], 
                              num_colors: int) -> None:
    """Initialize graph analysis and compute variable priorities"""
    start_time = time.time()
    
    # Create graph analyzer with adaptive complexity management
    self.graph_analyzer = GraphStructureAnalyzer(vertices, edges)
    
    # Compute centrality measures based on problem scale
    if len(vertices) <= self.preprocessing_threshold:
        # Full analysis for smaller problems
        degree_centrality = self.graph_analyzer.compute_degree_centrality()
        betweenness_centrality = self.graph_analyzer.compute_betweenness_centrality()
    else:
        # Lightweight analysis for larger problems
        degree_centrality = self.graph_analyzer.compute_degree_centrality()
        betweenness_centrality = {v: 0.0 for v in vertices}  # Skip expensive computation
    
    # Compute composite vertex priorities
    vertex_priorities = {}
    for vertex in vertices:
        degree_score = degree_centrality.get(vertex, 0.0)
        betweenness_score = betweenness_centrality.get(vertex, 0.0)
        vertex_priorities[vertex] = (
            self.centrality_weights['degree'] * degree_score + 
            self.centrality_weights['betweenness'] * betweenness_score
        )
    
    # Map vertex priorities to SAT variable priorities
    self.variable_priority_order = []
    sorted_vertices = sorted(vertices, key=lambda v: vertex_priorities[v], reverse=True)
    
    for vertex in sorted_vertices:
        for color in range(num_colors):
            sat_variable = vertex * num_colors + color + 1
            self.variable_priority_order.append(sat_variable)
    
    analysis_time = time.time() - start_time
    self.enhanced_stats['graph_analysis_time'] = analysis_time
    
    if self.verbose:
        print(f"Graph analysis completed in {analysis_time:.3f}s")
        print(f"Computed priorities for {len(vertices)} vertices")
\end{lstlisting}

\subsection{Graph-Aware Search Algorithm Implementation}
\label{appendix:graph-aware-search}

\begin{lstlisting}[language=Python, caption=Graph-Aware Search Algorithm with Robustness Focus]
def _choose_variable_with_graph_awareness(self, cnf_formula: List[List[int]], 
                                        assignments: Dict[int, bool]) -> Optional[int]:
    """Enhanced variable selection using graph priorities with fallback mechanisms"""
    if not self.variable_priority_order:
        self.enhanced_stats['fallback_activations'] += 1
        return self._pick_unassigned_variable(cnf_formula, assignments)
    
    # Check priority cache for previously computed selections
    cache_key = tuple(sorted(assignments.keys()))
    if hasattr(self, 'priority_cache') and cache_key in self.priority_cache:
        self.enhanced_stats['priority_cache_hits'] += 1
        cached_variable = self.priority_cache[cache_key]
        if cached_variable not in assignments:
            return cached_variable
    
    # Find highest priority unassigned variable
    for variable in self.variable_priority_order:
        if variable not in assignments:
            # Cache the selection for future use
            if not hasattr(self, 'priority_cache'):
                self.priority_cache = {}
            self.priority_cache[cache_key] = variable
            return variable
    
    # Fallback to baseline selection if no priority variables remain
    self.enhanced_stats['fallback_activations'] += 1
    return self._pick_unassigned_variable(cnf_formula, assignments)

def _solve_with_robustness_tracking(self, cnf_formula: List[List[int]], 
                                  timeout: float) -> Tuple[bool, Dict[int, bool]]:
    """
    Core solving algorithm with robustness tracking and timeout protection.
    Implements graph-aware DPLL with comprehensive failure prevention.
    """
    start_time = time.time()
    assignments = {}
    decision_level = 0
    decision_stack = []
    
    while True:
        # Timeout protection for robustness
        if time.time() - start_time > timeout:
            self.enhanced_stats['timeout_occurred'] = True
            return False, {}
        
        # Unit propagation with enhanced tracking
        try:
            assignments = self._unit_propagate_with_tracking(cnf_formula, assignments)
        except Exception as e:
            self.enhanced_stats['propagation_errors'] = self.enhanced_stats.get('propagation_errors', 0) + 1
            return False, {}
        
        # Check formula status
        status = self._check_formula_status(cnf_formula, assignments)
        
        if status == "SATISFIED":
            self.enhanced_stats['successful_completion'] = True
            return True, assignments
        elif status == "UNSATISFIED":
            if decision_level == 0:
                return False, {}
            
            # Enhanced backtracking with conflict analysis
            try:
                assignments, decision_level, decision_stack = self._enhanced_backtrack(
                    assignments, decision_level, decision_stack, cnf_formula
                )
            except Exception as e:
                self.enhanced_stats['backtrack_errors'] = self.enhanced_stats.get('backtrack_errors', 0) + 1
                return False, {}
            continue
        
        # Graph-aware variable selection
        variable = self._choose_variable_with_graph_awareness(cnf_formula, assignments)
        if variable is None:
            return False, {}
        
        # Enhanced decision making with robustness considerations
        value = self._make_robust_decision(variable, cnf_formula, assignments)
        
        # Record decision and continue
        assignments[variable] = value
        decision_level += 1
        decision_stack.append((variable, value, decision_level))
        self.enhanced_stats['enhanced_decisions'] += 1

def _make_robust_decision(self, variable: int, 
                        cnf_formula: List[List[int]], 
                        assignments: Dict[int, bool]) -> bool:
    """
    Make variable assignment decisions optimised for robustness rather than speed.
    """
    # Count positive and negative occurrences in unresolved clauses
    positive_count = 0
    negative_count = 0
    
    for clause in cnf_formula:
        # Skip already satisfied clauses
        if any(assignments.get(abs(lit), None) == (lit > 0) for lit in clause 
               if abs(lit) in assignments):
            continue
        
        # Count occurrences in unresolved clauses
        if variable in clause:
            positive_count += 1
        elif -variable in clause:
            negative_count += 1
    
    # Robust heuristic: choose assignment that satisfies more clauses
    # In case of tie, prefer positive assignment for consistency
    if positive_count >= negative_count:
        return True
    else:
        return False
\end{lstlisting}

\subsection{Memory Management and Profiling Implementation}
\label{appendix:memory-management}

\begin{lstlisting}[language=Python, caption=Memory Management and Profiling System]
class MemoryProfiler:
    """
    Comprehensive memory profiling and management for SAT solver components.
    Tracks memory usage patterns to ensure predictable resource consumption.
    """
    
    def __init__(self, enable_profiling: bool = True):
        self.enable_profiling = enable_profiling
        self.memory_snapshots = []
        self.component_usage = defaultdict(int)
        self.peak_memory = 0
        self.baseline_memory = 0
    
    def track_component_memory(self, component_name: str, 
                             data_structure: Any) -> None:
        """Track memory usage of specific solver components"""
        if not self.enable_profiling:
            return
        
        memory_usage = self._estimate_structure_size(data_structure)
        self.component_usage[component_name] = memory_usage
        
        # Update peak memory tracking
        total_usage = sum(self.component_usage.values())
        self.peak_memory = max(self.peak_memory, total_usage)
    
    def _estimate_structure_size(self, obj: Any) -> int:
        """
        Estimate memory usage of data structures without external dependencies.
        Provides approximate but consistent memory tracking.
        """
        import sys
        
        if isinstance(obj, dict):
            size = sys.getsizeof(obj)
            for key, value in obj.items():
                size += sys.getsizeof(key) + sys.getsizeof(value)
            return size
        elif isinstance(obj, (list, tuple, set)):
            size = sys.getsizeof(obj)
            for item in obj:
                size += sys.getsizeof(item)
            return size
        else:
            return sys.getsizeof(obj)
    
    def take_memory_snapshot(self, operation_name: str) -> None:
        """Capture memory state at specific solver operations"""
        if not self.enable_profiling:
            return
        
        try:
            import psutil
            import os
            
            process = psutil.Process(os.getpid())
            memory_info = process.memory_info()
            
            snapshot = {
                'operation': operation_name,
                'rss_bytes': memory_info.rss,
                'vms_bytes': memory_info.vms,
                'component_breakdown': dict(self.component_usage),
                'timestamp': time.time()
            }
            
            self.memory_snapshots.append(snapshot)
            
        except ImportError:
            # Fallback tracking without psutil
            snapshot = {
                'operation': operation_name,
                'estimated_usage': sum(self.component_usage.values()),
                'component_breakdown': dict(self.component_usage),
                'timestamp': time.time()
            }
            
            self.memory_snapshots.append(snapshot)
    
    def generate_memory_report(self) -> Dict[str, Any]:
        """Generate comprehensive memory usage analysis"""
        if not self.memory_snapshots:
            return {'error': 'No memory snapshots available'}
        
        if 'rss_bytes' in self.memory_snapshots[0]:
            peak_memory = max(snapshot['rss_bytes'] for snapshot in self.memory_snapshots)
            memory_growth = (self.memory_snapshots[-1]['rss_bytes'] - 
                           self.memory_snapshots[0]['rss_bytes'])
            
            return {
                'peak_memory_mb': peak_memory / (1024 * 1024),
                'memory_growth_mb': memory_growth / (1024 * 1024),
                'component_breakdown': dict(self.component_usage),
                'snapshot_count': len(self.memory_snapshots),
                'profiling_overhead_estimate': len(self.memory_snapshots) * 0.1  # MB
            }
        else:
            # Fallback report format
            peak_estimated = max(snapshot['estimated_usage'] for snapshot in self.memory_snapshots)
            
            return {
                'peak_estimated_bytes': peak_estimated,
                'component_breakdown': dict(self.component_usage),
                'snapshot_count': len(self.memory_snapshots),
                'note': 'Estimated values (psutil unavailable)'
            }
    
    def reset_profiling(self):
        """Reset all profiling data for fresh measurement"""
        self.memory_snapshots.clear()
        self.component_usage.clear()
        self.peak_memory = 0
\end{lstlisting}

\subsection{Robust Conflict Analysis Implementation}
\label{appendix:robust-conflict-analysis}

\begin{lstlisting}[language=Python, caption=Robust Conflict Analysis for Consistent Performance]
def _enhanced_conflict_analysis(self, conflict_clause: List[int], 
                              decision_stack: List[Tuple[int, bool, int]]) -> List[int]:
    """
    Enhanced conflict analysis incorporating graph structural information
    for improved learned clause quality and robustness.
    """
    if not decision_stack or not self.variable_priority_order:
        return conflict_clause
    
    # Extract variables from recent decisions
    recent_variables = set()
    for variable, value, level in decision_stack[-5:]:  # Last 5 decisions
        recent_variables.add(abs(variable))
    
    # Prioritise high-priority variables in conflict clause
    priority_map = {var: idx for idx, var in enumerate(self.variable_priority_order)}
    
    conflict_literals = []
    for literal in conflict_clause:
        variable = abs(literal)
        if variable in recent_variables:
            # Include recent decisions in learned clause
            conflict_literals.append(-literal)
        elif variable in priority_map and priority_map[variable] < 20:
            # Include high-priority variables
            conflict_literals.append(-literal)
    
    # Ensure learned clause is non-empty and useful
    if not conflict_literals:
        return conflict_clause
    
    return conflict_literals

def _enhanced_backtrack(self, assignments: Dict[int, bool], 
                       decision_level: int, 
                       decision_stack: List[Tuple[int, bool, int]], 
                       cnf_formula: List[List[int]]) -> Tuple[Dict[int, bool], int, List]:
    """
    Enhanced backtracking with conflict analysis and robustness improvements.
    """
    if not decision_stack:
        return assignments, 0, []
    
    # Identify conflict and perform analysis
    conflict_clause = self._identify_conflict_clause(cnf_formula, assignments)
    learned_clause = self._enhanced_conflict_analysis(conflict_clause, decision_stack)
    
    # Backtrack to appropriate level
    backtrack_level = max(0, decision_level - 1)
    
    # Remove assignments from current level
    new_assignments = assignments.copy()
    new_decision_stack = []
    
    for variable, value, level in decision_stack:
        if level <= backtrack_level:
            new_decision_stack.append((variable, value, level))
        else:
            # Remove assignment from current level
            if variable in new_assignments:
                del new_assignments[variable]
    
    # Add learned clause to formula for future conflict avoidance
    if learned_clause and len(learned_clause) <= 10:  # Limit clause size for efficiency
        cnf_formula.append(learned_clause)
        self.enhanced_stats['learned_clauses'] = self.enhanced_stats.get('learned_clauses', 0) + 1
    
    return new_assignments, backtrack_level, new_decision_stack

def _identify_conflict_clause(self, cnf_formula: List[List[int]], 
                            assignments: Dict[int, bool]) -> List[int]:
    """
    Identify the conflict clause for enhanced conflict analysis.
    """
    for clause in cnf_formula:
        if all(assignments.get(abs(lit), None) is not None and 
               assignments[abs(lit)] != (lit > 0) for lit in clause):
            return clause
    
    # Return empty conflict if none found
    return []
\end{lstlisting}

\subsection{Integration Challenge Resolution Implementation}
\label{appendix:integration-challenges}

\begin{lstlisting}[language=Python, caption=Integration Challenge Resolution Implementation]
def _dpll_with_enhanced_ordering(self, cnf_formula: List[List[int]], 
                               assignments: Dict[int, bool]) -> Tuple[bool, Dict[int, bool]]:
    """DPLL with graph-aware variable ordering integration"""
    # Preserve original DPLL structure whilst enhancing variable selection
    propagated_formula, new_assignments = self._unit_propagation(cnf_formula, assignments.copy())
    assignments.update(new_assignments)
    
    # Maintain DPLL termination conditions
    if self._is_formula_satisfied(propagated_formula, assignments):
        return True, assignments
    
    if self._has_empty_clause(propagated_formula, assignments):
        return False, {}
    
    # Enhanced variable selection with fallback
    variable = self._choose_variable_with_graph_awareness(propagated_formula, assignments)
    if variable is None:
        return False, {}
    
    # Try positive assignment first
    positive_assignments = assignments.copy()
    positive_assignments[variable] = True
    
    satisfiable, solution = self._dpll_with_enhanced_ordering(
        propagated_formula, positive_assignments
    )
    
    if satisfiable:
        return True, solution
    
    # Try negative assignment
    negative_assignments = assignments.copy()
    negative_assignments[variable] = False
    
    return self._dpll_with_enhanced_ordering(propagated_formula, negative_assignments)

def _synchronize_with_baseline(self, baseline_solver: 'DPLLSolver') -> None:
    """
    Synchronise enhanced solver state with baseline for compatibility testing.
    Ensures consistent behaviour whilst maintaining robustness improvements.
    """
    # Synchronise common statistics
    if hasattr(baseline_solver, 'statistics'):
        shared_stats = {}
        for key in ['decisions', 'conflicts', 'unit_propagations']:
            if key in baseline_solver.statistics:
                shared_stats[key] = baseline_solver.statistics[key]
        
        # Merge with enhanced statistics
        self.enhanced_stats.update(shared_stats)
    
    # Synchronise timeout handling
    if hasattr(baseline_solver, 'timeout_occurred'):
        self.enhanced_stats['baseline_timeout'] = baseline_solver.timeout_occurred
    
    # Maintain interface compatibility
    if hasattr(baseline_solver, 'verbose'):
        self.verbose = baseline_solver.verbose

def _validate_interface_compatibility(self) -> Dict[str, bool]:
    """
    Validate that enhanced solver maintains interface compatibility
    with existing solver infrastructure.
    """
    compatibility_checks = {
        'dpll_solver_inheritance': isinstance(self, DPLLSolver),
        'solve_method_present': hasattr(self, 'solve'),
        'statistics_accessible': hasattr(self, 'get_statistics'),
        'verbose_mode_supported': hasattr(self, 'verbose'),
        'timeout_handling_present': 'timeout_occurred' in dir(self) or hasattr(self, 'enhanced_stats')
    }
    
    # Additional method signature checks
    import inspect
    
    if hasattr(self, 'solve'):
        solve_signature = inspect.signature(self.solve)
        compatibility_checks['solve_signature_valid'] = len(solve_signature.parameters) >= 1
    
    return compatibility_checks
\end{lstlisting>

\subsection{Comprehensive Statistics and Monitoring}
\label{appendix:comprehensive-statistics}

\begin{lstlisting}[language=Python, caption=Comprehensive Statistics and Monitoring Implementation]
def get_comprehensive_statistics(self) -> Dict[str, Any]:
    """Retrieve detailed solving statistics including graph-aware metrics"""
    base_stats = {}
    if hasattr(super(), 'get_statistics'):
        base_stats = super().get_statistics()
    
    combined_stats = {
        # Traditional SAT metrics
        'decisions': base_stats.get('decisions', 0),
        'conflicts': base_stats.get('conflicts', 0),
        'unit_propagations': base_stats.get('unit_propagations', 0),
        
        # Graph-aware enhancements
        'graph_analysis_time': self.enhanced_stats.get('graph_analysis_time', 0.0),
        'enhanced_decisions': self.enhanced_stats.get('enhanced_decisions', 0),
        'priority_cache_hits': self.enhanced_stats.get('priority_cache_hits', 0),
        'fallback_activations': self.enhanced_stats.get('fallback_activations', 0),
        'learned_clauses': self.enhanced_stats.get('learned_clauses', 0),
        
        # Robustness metrics
        'successful_completion': self.enhanced_stats.get('successful_completion', False),
        'timeout_occurred': self.enhanced_stats.get('timeout_occurred', False),
        'propagation_errors': self.enhanced_stats.get('propagation_errors', 0),
        'backtrack_errors': self.enhanced_stats.get('backtrack_errors', 0),
        
        # Performance ratios
        'enhancement_ratio': 0.0,
        'analysis_overhead': 0.0,
        'cache_hit_rate': 0.0
    }
    
    # Calculate derived metrics
    total_decisions = max(combined_stats['decisions'], 1)
    combined_stats['enhancement_ratio'] = (
        combined_stats['enhanced_decisions'] / total_decisions
    )
    
    total_time = self.enhanced_stats.get('total_time', 1.0)
    combined_stats['analysis_overhead'] = (
        combined_stats['graph_analysis_time'] / total_time
    )
    
    total_selections = combined_stats['enhanced_decisions'] + combined_stats['fallback_activations']
    if total_selections > 0:
        combined_stats['cache_hit_rate'] = (
            combined_stats['priority_cache_hits'] / total_selections
        )
    
    return combined_stats

def generate_performance_report(self) -> str:
    """
    Generate human-readable performance report for analysis and debugging.
    """
    stats = self.get_comprehensive_statistics()
    
    report = []
    report.append("=== Enhanced SAT Solver Performance Report ===")
    report.append("")
    
    # Basic solving statistics
    report.append("Basic Solving Statistics:")
    report.append(f"  Total Decisions: {stats['decisions']}")
    report.append(f"  Enhanced Decisions: {stats['enhanced_decisions']}")
    report.append(f"  Conflicts: {stats['conflicts']}")
    report.append(f"  Unit Propagations: {stats['unit_propagations']}")
    report.append(f"  Learned Clauses: {stats['learned_clauses']}")
    report.append("")
    
    # Graph-aware performance
    report.append("Graph-Aware Performance:")
    report.append(f"  Graph Analysis Time: {stats['graph_analysis_time']:.3f}s")
    report.append(f"  Priority Cache Hits: {stats['priority_cache_hits']}")
    report.append(f"  Fallback Activations: {stats['fallback_activations']}")
    report.append(f"  Cache Hit Rate: {stats['cache_hit_rate']:.2%}")
    report.append("")
    
    # Robustness metrics
    report.append("Robustness Metrics:")
    report.append(f"  Successful Completion: {stats['successful_completion']}")
    report.append(f"  Timeout Occurred: {stats['timeout_occurred']}")
    report.append(f"  Propagation Errors: {stats['propagation_errors']}")
    report.append(f"  Backtrack Errors: {stats['backtrack_errors']}")
    report.append("")
    
    # Performance ratios
    report.append("Performance Ratios:")
    report.append(f"  Enhancement Ratio: {stats['enhancement_ratio']:.2%}")
    report.append(f"  Analysis Overhead: {stats['analysis_overhead']:.2%}")
    report.append("")
    
    # Recommendations
    report.append("Recommendations:")
    if stats['fallback_activations'] > stats['enhanced_decisions'] * 0.2:
        report.append("  - Consider adjusting graph analysis threshold")
    if stats['cache_hit_rate'] < 0.3:
        report.append("  - Cache efficiency could be improved")
    if stats['analysis_overhead'] > 0.25:
        report.append("  - Graph analysis overhead is significant")
    if not stats['successful_completion'] and not stats['timeout_occurred']:
        report.append("  - Investigate solving failures")
    
    return "\n".join(report)
\end{lstlisting}

\section{Specialised Testing Components Code}
\label{appendix:specialised-testing-components}

\subsection{Stress Testing Framework Implementation}
\label{appendix:stress-testing}

\begin{lstlisting}[language=Python, caption=Stress Testing Framework for Worst-Case Validation]
class StressTester:
    """
    Generates increasingly challenging graph structures that systematically 
    push baseline solvers towards timeout failure whilst evaluating enhanced solver resilience.
    """
    
    def __init__(self, random_seed: int = 42):
        self.random_seed = random_seed
        self.stress_test_catalogue = []
        random.seed(random_seed)
        
    def generate_progressive_stress_tests(self, base_vertices: int = 50) -> List[Dict]:
        """
        Generate stress tests with progressive difficulty escalation.
        """
        stress_tests = []
        
        # Dense random graphs with increasing connectivity
        for density in [0.3, 0.5, 0.7, 0.8, 0.9]:
            stress_tests.append(self._create_dense_random_graph(base_vertices, density))
        
        # High-connectivity regular structures
        for degree in range(3, min(base_vertices // 2, 15)):
            stress_tests.append(self._create_regular_graph(base_vertices, degree))
        
        # Pathological instances designed to defeat baseline approaches
        stress_tests.extend(self._create_pathological_instances(base_vertices))
        
        return stress_tests
    
    def _create_dense_random_graph(self, n_vertices: int, density: float) -> Dict:
        """
        Create dense random graph designed to stress variable ordering heuristics.
        """
        vertices = list(range(n_vertices))
        edges = []
        
        # Generate edges based on density
        total_possible_edges = n_vertices * (n_vertices - 1) // 2
        target_edges = int(density * total_possible_edges)
        
        edge_set = set()
        attempts = 0
        while len(edge_set) < target_edges and attempts < target_edges * 10:
            u = random.randint(0, n_vertices - 1)
            v = random.randint(0, n_vertices - 1)
            if u != v:
                edge = tuple(sorted([u, v]))
                edge_set.add(edge)
            attempts += 1
        
        edges = list(edge_set)
        
        # Calculate chromatic number estimate (conservative upper bound)
        max_degree = max(len([e for e in edges if u in e]) for u in vertices)
        chromatic_estimate = max_degree + 1
        
        return {
            'id': f'dense_random_{n_vertices}_{density:.1f}',
            'vertices': vertices,
            'edges': edges,
            'colors': chromatic_estimate,
            'metadata': {
                'graph_type': 'dense_random',
                'density': density,
                'difficulty': 'stress',
                'expected_baseline_failure': density > 0.6
            }
        }
    
    def _create_regular_graph(self, n_vertices: int, degree: int) -> Dict:
        """
        Create regular graph with specified degree for connectivity stress testing.
        """
        if degree >= n_vertices:
            degree = n_vertices - 1
        
        vertices = list(range(n_vertices))
        edges = set()
        
        # Create regular structure
        for vertex in vertices:
            connections = 0
            offset = 1
            while connections < degree and offset < n_vertices:
                neighbour = (vertex + offset) % n_vertices
                if neighbour != vertex:
                    edge = tuple(sorted([vertex, neighbour]))
                    edges.add(edge)
                    connections += 1
                offset += 1
        
        edges = list(edges)
        
        return {
            'id': f'regular_{n_vertices}_{degree}',
            'vertices': vertices,
            'edges': edges,
            'colors': degree + 1,
            'metadata': {
                'graph_type': 'regular',
                'degree': degree,
                'difficulty': 'stress' if degree > 8 else 'moderate'
            }
        }
    
    def _create_pathological_instances(self, n_vertices: int) -> List[Dict]:
        """
        Create pathological instances specifically designed to expose 
        baseline solver limitations.
        """
        pathological_cases = []
        
        # Complete graph (worst case for graph colouring)
        if n_vertices <= 20:  # Only for small instances due to exponential growth
            vertices = list(range(n_vertices))
            edges = [(i, j) for i in range(n_vertices) for j in range(i + 1, n_vertices)]
            
            pathological_cases.append({
                'id': f'complete_{n_vertices}',
                'vertices': vertices,
                'edges': edges,
                'colors': n_vertices,
                'metadata': {
                    'graph_type': 'complete',
                    'difficulty': 'pathological',
                    'expected_baseline_failure': True
                }
            })
        
        # Highly connected bipartite-like structure
        partition_size = n_vertices // 2
        vertices = list(range(n_vertices))
        edges = []
        
        # Connect most vertices in first partition to most in second partition
        for i in range(partition_size):
            for j in range(partition_size, min(n_vertices, partition_size + 15)):
                edges.append((i, j))
        
        pathological_cases.append({
            'id': f'dense_bipartite_{n_vertices}',
            'vertices': vertices,
            'edges': edges,
            'colors': max(partition_size, 15),
            'metadata': {
                'graph_type': 'dense_bipartite',
                'difficulty': 'pathological'
            }
        })
        
        return pathological_cases
    
    def execute_stress_test_suite(self, baseline_solver, enhanced_solver, 
                                stress_tests: List[Dict], timeout: float = 15.0) -> Dict:
        """
        Execute stress test suite with failure mode documentation.
        """
        stress_results = {
            'total_tests': len(stress_tests),
            'baseline_failures': 0,
            'enhanced_failures': 0,
            'robustness_improvements': [],
            'failure_mode_analysis': []
        }
        
        for test_case in stress_tests:
            print(f"Executing stress test: {test_case['id']}")
            
            # Test baseline solver
            baseline_result = self._execute_with_failure_analysis(
                baseline_solver, test_case, timeout
            )
            
            # Test enhanced solver
            enhanced_result = self._execute_with_failure_analysis(
                enhanced_solver, test_case, timeout
            )
            
            # Analyse results
            if baseline_result['timed_out'] or not baseline_result['success']:
                stress_results['baseline_failures'] += 1
            
            if enhanced_result['timed_out'] or not enhanced_result['success']:
                stress_results['enhanced_failures'] += 1
            
            # Document robustness improvement
            if (baseline_result['timed_out'] and not enhanced_result['timed_out']):
                improvement = {
                    'test_id': test_case['id'],
                    'improvement_type': 'timeout_avoidance',
                    'baseline_failed': True,
                    'enhanced_succeeded': enhanced_result['success']
                }
                stress_results['robustness_improvements'].append(improvement)
            
            # Document failure modes
            failure_analysis = {
                'test_id': test_case['id'],
                'baseline_behaviour': baseline_result,
                'enhanced_behaviour': enhanced_result,
                'robustness_demonstrated': baseline_result['timed_out'] and not enhanced_result['timed_out']
            }
            stress_results['failure_mode_analysis'].append(failure_analysis)
        
        # Calculate summary statistics
        stress_results['baseline_success_rate'] = (
            (stress_results['total_tests'] - stress_results['baseline_failures']) / 
            stress_results['total_tests']
        )
        stress_results['enhanced_success_rate'] = (
            (stress_results['total_tests'] - stress_results['enhanced_failures']) / 
            stress_results['total_tests']
        )
        stress_results['robustness_improvement_count'] = len(stress_results['robustness_improvements'])
        
        return stress_results
    
    def _execute_with_failure_analysis(self, solver, test_case: Dict, timeout: float) -> Dict:
        """
        Execute solver with detailed failure mode analysis.
        """
        start_time = time.time()
        
        try:
            success, coloring, stats = solver.solve_graph_coloring(
                test_case['vertices'], test_case['edges'], test_case['colors'], timeout
            )
            
            execution_time = time.time() - start_time
            timed_out = execution_time >= timeout * 0.95  # 95% of timeout threshold
            
            return {
                'success': success,
                'execution_time': execution_time,
                'timed_out': timed_out,
                'solver_stats': stats,
                'failure_mode': 'timeout' if timed_out else ('unsatisfiable' if not success else None)
            }
            
        except Exception as e:
            return {
                'success': False,
                'execution_time': time.time() - start_time,
                'timed_out': False,
                'error': str(e),
                'failure_mode': 'exception'
            }
\end{lstlisting} = self._check_formula_status(cnf_formula, assignments)
        
        if status == "SATISFIED":
            self.enhanced_stats['successful_completion'] = True
            return True, assignments
        elif status == "UNSATISFIED":
            if decision_level == 0:
                return False, {}
            
            # Enhanced backtracking with conflict analysis
            try:
                assignments, decision_level, decision_stack = self._enhanced_backtrack(
                    assignments, decision_level, decision_stack, cnf_formula
                )
            except Exception as e:
                self.enhanced_stats['backtrack_errors'] = self.enhanced_stats.get('backtrack_errors', 0) + 1
                return False, {}
            continue
        
        # Graph-aware variable selection
        variable = self._choose_variable_with_graph_awareness(cnf_formula, assignments)
        if variable is None:
            return False, {}
        
        # Enhanced decision making with robustness considerations
        value = self._make_robust_decision(variable, cnf_formula, assignments)
        
        # Record decision and continue
        assignments[variable] = value
        decision_level += 1
        decision_stack.append((variable, value, decision_level))
        self.enhanced_stats['enhanced_decisions'] += 1
\end{lstlisting}

\subsection{Robustness-Oriented Graph Analysis Pipeline}
\label{appendix:robustness-oriented-analysis}

\begin{lstlisting}[language=Python, caption=Robustness-Oriented Graph Analysis Pipeline]
class RobustnessOrientedAnalyzer:
    """
    Graph analysis pipeline designed to maximize robustness insights
    while accepting computational overhead for comprehensive analysis.
    """
    
    def __init__(self, thoroughness_level: str = 'comprehensive'):
        self.thoroughness_level = thoroughness_level
        self.analysis_cache = {}
        self.computation_budget = self._set_computation_budget()
        
    def perform_comprehensive_analysis(self, vertices: List[int], 
                                     edges: List[Tuple[int, int]]) -> RobustnessAnalysis:
        """
        Comprehensive graph analysis optimized for robustness rather than speed.
        """
        analysis_start = time.time()
        
        # Phase 1: Structural characterization (accept overhead for completeness)
        structural_props = self._compute_comprehensive_structural_properties(vertices, edges)
        
        # Phase 2: Centrality analysis (thorough computation for robust priorities)
        centrality_measures = self._compute_multiple_centrality_measures(vertices, edges)
        
        # Phase 3: Connectivity analysis (identify potential failure points)
        connectivity_analysis = self._analyze_connectivity_robustness(vertices, edges)
        
        # Phase 4: Priority synthesis (combine multiple measures for robustness)
        robust_priorities = self._synthesize_robust_variable_priorities(
            structural_props, centrality_measures, connectivity_analysis
        )
        
        analysis_time = time.time() - analysis_start
        
        return RobustnessAnalysis(
            structural_properties=structural_props,
            centrality_measures=centrality_measures,
            connectivity_analysis=connectivity_analysis,
            variable_priorities=robust_priorities,
            analysis_overhead=analysis_time,
            robustness_confidence=self._assess_robustness_confidence(
                structural_props, connectivity_analysis
            )
        )
    
    def _compute_multiple_centrality_measures(self, vertices: List[int], 
                                           edges: List[Tuple[int, int]]) -> Dict[str, Dict[int, float]]:
        """
        Compute multiple centrality measures for robust variable prioritization.
        Accepts computational overhead for comprehensive structural understanding.
        """
        centrality_results = {}
        
        # Always compute degree centrality (fast baseline)
        centrality_results['degree'] = self._compute_degree_centrality(vertices, edges)
        
        # Compute betweenness centrality for moderate-scale problems
        if len(vertices) <= 100:  # Accept overhead for robustness
            centrality_results['betweenness'] = self._compute_betweenness_centrality(vertices, edges)
        else:
            centrality_results['betweenness'] = {v: 0.0 for v in vertices}
        
        # Compute closeness centrality for additional robustness
        if len(vertices) <= 80:  # Additional overhead for enhanced robustness
            centrality_results['closeness'] = self._compute_closeness_centrality(vertices, edges)
        else:
            centrality_results['closeness'] = {v: 0.0 for v in vertices}
        
        # Compute eigenvector centrality for comprehensive analysis
        if len(vertices) <= 60 and self.thoroughness_level == 'comprehensive':
            centrality_results['eigenvector'] = self._compute_eigenvector_centrality(vertices, edges)
        else:
            centrality_results['eigenvector'] = {v: 0.0 for v in vertices}
        
        return centrality_results
    
    def _synthesize_robust_variable_priorities(self, structural_props: Dict, 
                                             centrality_measures: Dict[str, Dict[int, float]], 
                                             connectivity_analysis: Dict) -> List[int]:
        """
        Synthesize variable priorities optimized for robustness rather than speed.
        """
        vertex_scores = {}
        
        for vertex in structural_props['vertices']:
            # Weighted combination emphasizing robustness indicators
            degree_score = centrality_measures['degree'].get(vertex, 0.0) * 0.4
            betweenness_score = centrality_measures['betweenness'].get(vertex, 0.0) * 0.3
            closeness_score = centrality_measures['closeness'].get(vertex, 0.0) * 0.2
            eigenvector_score = centrality_measures['eigenvector'].get(vertex, 0.0) * 0.1
            
            # Add robustness-specific bonuses
            if vertex in connectivity_analysis.get('critical_vertices', []):
                robustness_bonus = 0.2  # Prioritize structurally critical vertices
            else:
                robustness_bonus = 0.0
            
            vertex_scores[vertex] = (
                degree_score + betweenness_score + closeness_score + 
                eigenvector_score + robustness_bonus
            )
        
        # Return vertices sorted by robustness-oriented priority
        return sorted(structural_props['vertices'], 
                     key=lambda v: vertex_scores[v], reverse=True)
\end{lstlisting}

\subsection{Trade-off Monitoring and Analysis Framework}
\label{appendix:tradeoff-monitoring}

\begin{lstlisting}[language=Python, caption=Trade-off Monitoring and Analysis Framework]
class TradeoffAnalyzer:
    """
    Comprehensive framework for monitoring and analyzing performance-robustness trade-offs
    in graph-aware SAT solving applications.
    """
    
    def __init__(self):
        self.baseline_metrics = {}
        self.enhanced_metrics = {}
        self.tradeoff_history = []
        
    def analyze_comprehensive_tradeoff(self, baseline_result: SolverResult, 
                                     enhanced_result: SolverResult, 
                                     problem_characteristics: Dict) -> TradeoffAnalysis:
        """
        Comprehensive analysis of performance-robustness trade-offs with statistical validation.
        """
        # Performance impact analysis
        performance_analysis = self._analyze_performance_impact(baseline_result, enhanced_result)
        
        # Robustness improvement analysis
        robustness_analysis = self._analyze_robustness_improvements(baseline_result, enhanced_result)
        
        # Cost-benefit calculation
        cost_benefit = self._calculate_cost_benefit_ratio(performance_analysis, robustness_analysis)
        
        # Statistical significance testing
        statistical_validation = self._validate_tradeoff_significance(
            baseline_result, enhanced_result, problem_characteristics
        )
        
        # Deployment recommendation
        deployment_guidance = self._generate_deployment_recommendation(
            cost_benefit, statistical_validation, problem_characteristics
        )
        
        return TradeoffAnalysis(
            overhead_factor=performance_analysis['overhead_factor'],
            robustness_improvement=robustness_analysis['success_rate_improvement'],
            cost_benefit_ratio=cost_benefit,
            statistical_confidence=statistical_validation['confidence_level'],
            deployment_recommendation=deployment_guidance,
            detailed_metrics={
                'performance': performance_analysis,
                'robustness': robustness_analysis,
                'validation': statistical_validation
            }
        )
    
    def _analyze_performance_impact(self, baseline: SolverResult, 
                                  enhanced: SolverResult) -> Dict[str, float]:
        """
        Detailed analysis of performance overhead components and their contributions.
        """
        if baseline.execution_time == 0:
            overhead_factor = float('inf') if enhanced.execution_time > 0 else 1.0
        else:
            overhead_factor = enhanced.execution_time / baseline.execution_time
        
        preprocessing_overhead = enhanced.preprocessing_time / max(baseline.execution_time, 0.001)
        analysis_overhead = enhanced.analysis_time / max(baseline.execution_time, 0.001)
        search_overhead = (enhanced.search_time - baseline.search_time) / max(baseline.execution_time, 0.001)
        
        return {
            'overhead_factor': overhead_factor,
            'preprocessing_overhead_ratio': preprocessing_overhead,
            'analysis_overhead_ratio': analysis_overhead,
            'search_overhead_ratio': search_overhead,
            'total_overhead_seconds': enhanced.execution_time - baseline.execution_time
        }
    
    def _analyze_robustness_improvements(self, baseline: SolverResult, 
                                       enhanced: SolverResult) -> Dict[str, float]:
        """
        Quantitative analysis of robustness improvements and reliability enhancements.
        """
        baseline_success = 1.0 if baseline.satisfiable is not None else 0.0
        enhanced_success = 1.0 if enhanced.satisfiable is not None else 0.0
        
        success_rate_improvement = enhanced_success - baseline_success
        
        # Timeout avoidance analysis
        baseline_timeout = 1.0 if baseline.timed_out else 0.0
        enhanced_timeout = 1.0 if enhanced.timed_out else 0.0
        timeout_avoidance = baseline_timeout - enhanced_timeout
        
        # Decision efficiency analysis
        decision_efficiency = self._calculate_decision_efficiency(baseline, enhanced)
        
        return {
            'success_rate_improvement': success_rate_improvement,
            'timeout_avoidance': timeout_avoidance,
            'decision_efficiency': decision_efficiency,
            'reliability_score': (success_rate_improvement + timeout_avoidance) / 2.0
        }
    
    def _generate_deployment_recommendation(self, cost_benefit: float, 
                                          statistical_validation: Dict, 
                                          problem_characteristics: Dict) -> str:
        """
        Generate evidence-based deployment recommendations based on trade-off analysis.
        """
        confidence = statistical_validation['confidence_level']
        problem_difficulty = problem_characteristics.get('difficulty_rating', 'moderate')
        
        if cost_benefit > 0.5 and confidence > 0.8:
            if problem_difficulty == 'high':
                return 'strongly_recommend_enhanced'
            else:
                return 'recommend_enhanced'
        elif cost_benefit > 0.2 and confidence > 0.6:
            return 'conditionally_recommend_enhanced'
        elif cost_benefit > 0.0:
            return 'evaluate_case_by_case'
        else:
            return 'recommend_baseline'
\end{lstlisting}

\section{Core Graph Analysis Implementation Code}
\label{appendix:core-graph-analysis}

\subsection{GraphStructureAnalyzer Implementation}
\label{appendix:graph-structure-analyzer}

\begin{lstlisting}[language=Python, caption=Complete Graph Structure Analyzer Implementation]
class GraphStructureAnalyzer:
    """
    Comprehensive graph analysis for SAT solver optimisation.
    Provides all graph-theoretic analysis needed for implementing
    graph-aware heuristics without external dependencies.
    """
    
    def __init__(self, vertices: List[int], edges: List[Tuple[int, int]]):
        self.vertices = set(vertices)
        self.edges = set(edges)
        self.adjacency = defaultdict(set)
        self.degree_map = {}
        self._build_adjacency_structure()
    
    def _build_adjacency_structure(self):
        """Build efficient adjacency representation for graph operations"""
        for u, v in self.edges:
            self.adjacency[u].add(v)
            self.adjacency[v].add(u)
        
        # Compute degree map for O(1) degree access
        for vertex in self.vertices:
            self.degree_map[vertex] = len(self.adjacency[vertex])
    
    def compute_degree_centrality(self) -> Dict[int, float]:
        """
        Compute normalised degree centrality for all vertices.
        Critical for graph-aware variable ordering in SAT solving.
        """
        n = len(self.vertices)
        if n <= 1:
            return {v: 0.0 for v in self.vertices}
        
        centrality = {}
        for vertex in self.vertices:
            degree = self.degree_map[vertex]
            centrality[vertex] = degree / (n - 1)
        
        return centrality
    
    def compute_betweenness_centrality(self) -> Dict[int, float]:
        """
        Compute betweenness centrality using efficient shortest path algorithms.
        Identifies structurally important vertices for prioritised variable ordering.
        """
        centrality = {vertex: 0.0 for vertex in self.vertices}
        
        for source in self.vertices:
            # Single-source shortest paths using BFS
            stack = []
            paths = {vertex: [] for vertex in self.vertices}
            sigma = {vertex: 0.0 for vertex in self.vertices}
            distance = {vertex: -1 for vertex in self.vertices}
            delta = {vertex: 0.0 for vertex in self.vertices}
            
            sigma[source] = 1.0
            distance[source] = 0
            queue = deque([source])
            
            # BFS to find shortest paths
            while queue:
                vertex = queue.popleft()
                stack.append(vertex)
                
                for neighbour in self.adjacency[vertex]:
                    # First time we encounter this vertex
                    if distance[neighbour] < 0:
                        queue.append(neighbour)
                        distance[neighbour] = distance[vertex] + 1
                    
                    # Shortest path to neighbour via vertex
                    if distance[neighbour] == distance[vertex] + 1:
                        sigma[neighbour] += sigma[vertex]
                        paths[neighbour].append(vertex)
            
            # Accumulation phase
            while stack:
                vertex = stack.pop()
                for predecessor in paths[vertex]:
                    delta[predecessor] += (sigma[predecessor] / sigma[vertex]) * (1 + delta[vertex])
                
                if vertex != source:
                    centrality[vertex] += delta[vertex]
        
        # Normalisation for undirected graphs
        n = len(self.vertices)
        if n > 2:
            normalisation_factor = 2.0 / ((n - 1) * (n - 2))
            for vertex in centrality:
                centrality[vertex] *= normalisation_factor
        
        return centrality
    
    def compute_closeness_centrality(self) -> Dict[int, float]:
        """
        Compute closeness centrality for additional robustness metrics.
        """
        centrality = {}
        
        for vertex in self.vertices:
            # BFS for shortest path distances
            distances = {v: float('inf') for v in self.vertices}
            distances[vertex] = 0
            queue = deque([vertex])
            
            while queue:
                current = queue.popleft()
                for neighbour in self.adjacency[current]:
                    if distances[neighbour] == float('inf'):
                        distances[neighbour] = distances[current] + 1
                        queue.append(neighbour)
            
            # Calculate closeness centrality
            total_distance = sum(d for d in distances.values() if d != float('inf'))
            reachable_nodes = sum(1 for d in distances.values() if d != float('inf')) - 1
            
            if reachable_nodes > 0 and total_distance > 0:
                centrality[vertex] = reachable_nodes / total_distance
            else:
                centrality[vertex] = 0.0
        
        return centrality
    
    def analyze_structural_properties(self) -> Dict[str, float]:
        """
        Comprehensive structural analysis for adaptive parameter tuning.
        """
        n_vertices = len(self.vertices)
        n_edges = len(self.edges)
        
        # Basic graph metrics
        density = (2 * n_edges) / (n_vertices * (n_vertices - 1)) if n_vertices > 1 else 0
        average_degree = (2 * n_edges) / n_vertices if n_vertices > 0 else 0
        
        # Degree distribution analysis
        degrees = list(self.degree_map.values())
        max_degree = max(degrees) if degrees else 0
        min_degree = min(degrees) if degrees else 0
        degree_variance = sum((d - average_degree) ** 2 for d in degrees) / len(degrees) if degrees else 0
        
        return {
            'vertex_count': n_vertices,
            'edge_count': n_edges,
            'density': density,
            'average_degree': average_degree,
            'max_degree': max_degree,
            'min_degree': min_degree,
            'degree_variance': degree_variance,
            'connectivity_complexity': density * degree_variance
        }
\end{lstlisting}
